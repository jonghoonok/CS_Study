# OS

운영체제 기초부터 심화까지



참고서적

- 운영체제와 정보기술의 원리 [강의](http://www.kocw.net/home/search/kemView.do?kemId=1046323)
- Operating Systems: Three Easy Pieces



[TOC]

## 1. 운영체제의 역할



- 시스템 자원(CPU, 메모리, I/O device, 저장매체) 관리
  - 각 프로그램이 CPU를 얼마나 사용해야 하는가?
  - 각 프로그램이 메모리의 어디에 얼마나 공간을 차지하는가?
  - 입력된 데이터를 어떤 프로그램이 사용하는가? 출력을 어떻게 하는가?
  - 어디에 어떻게 저장하는가?
- 사용자-컴퓨터 간 커뮤니케이션 지원
- 하드웨어와 **응용프로그램** 제어
  - 프로세스 관리, 램 관리, 파일 관리, 디스크 관리, 입출력 관리, 네트워킹/보안
  - 응용프로그램(Application)이란?
    - 소프트웨어에서 OS를 제외한 나머지
  - OS는 응용프로그램을 **실행**하고, **권한**을 관리함
    - 응용 프로그램이 요청하는 시스템 리소스를 효율적으로 분배



### 1.1. OS의 역사

- 60년대 batch processing system(순차 처리) 탄생: 운영체제의 출현
- 60년대 후반 time sharing system, multi tasking 개념 탄생(구현x)
  - 시분할: 다중 사용자 지원 시 **컴퓨터 응답시간** 을 줄일 필요성에 따라 도입
    - 예) 프로그램 실행 중 키보드를 눌렀을 때 화면에 표시되기까지 시간
    - 시분할 시스템에서 시간을 잘게 쪼갤 수록 응답시간이 빨라짐
  - 멀티태스킹: CPU의 활용도 극대화
    - 여러 응용프로그램의 병렬 실행: 이것도 시분할을 이용
    - 멀티프로그래밍: 입출력 등 CPU**안 쓰는 시간에 다른 작업 실행**
- 70년대 UNIX의 탄생: 현대 운영체제 기술 확립(시분할, 멀티 태스킹)
  - C언어가 개발되면서 기존 어셈블리어가 가진 단점(메모리에 직접 할당하기 때문에 하드웨어가 달라지면 재코딩)이 극복되어 범용적 소프트웨어 개발이 가능해짐
- 80년대 PC의 탄생: 터미널 환경 CLI -> GUI(84' Macintosh)
- 90년대 
  - 응용프로그램(엑셀, 워드) 보급과 Windows의 대중화
    - 엑셀을 위해 windows를 사고 위닝을 위해 PS를 삼: killer application
  - 네트워크 기술 발전: www
  - 오픈 소스 운동 활성화: LINUX
- 2000년 이후
  - 오픈 소스 활성화: LINUX, Apache, MySQL, Android, 딥러닝, IoT 관련
  - 가상 머신(한 컴퓨터에 여러 OS 설치), 대용량 병렬 처리 활성화(멀티 코어)



#### 운영체제 구조

> 사용자 - 응용프로그램/쉘 - API - 시스템콜 - OS - hardware
>
> 플랫폼, 쉘, 컴파일러 이런애들을 시스템 소프트웨어라고 함

- 사용자 인터페이스
  - 쉘: 사용자가 OS기능과 서비스를 조작할 수 있게 인터페이스 제공
  - 쉘은 터미널 환경과 GUI환경 두 종류로 분류
- 응용프로그램 인터페이스(API)
  - 함수의 집합: 각 "언어 별"로 OS조작하는 함수 존재(`open()` 등)
  - 함수들을 묶어서 라이브러리 형태가 제공됨(C library 등)
    - 리눅스는 어차피 C로 만들었기 때문에 시스템 콜을 직접 사용할 수도 있으나 범용성을 위해 C API가 사용됨
- **시스템 콜** or 시스템 호출 인터페이스
  - OS의 각 기능을 사용할 수 있도록 시스템 콜이라는 함수를 제공
  - API는 내부에서 시스템 콜을 호출
  - 시스템 콜 정의
    - **POSIX** API, 윈도우 API를 기본으로 각각의 OS에 대한 시스템 콜 개발
    - POSIX란 이식 가능 운영 체제 인터페이스를 뜻하며 서로 다른 유닉스 OS의  공통 API를 정리한 규격
- CPU Protection Rings
  - CPU의 권한 모드(사용자 모드: 일반 사용, **커널** 모드: 특권 명령어 실행 및 원하는 작업 수행을 위한 자원 접근 가능 모드)
    - 보통 4개의 링으로 구성되며 핵심인 ring0 커널을 둘러싸고 있음
    - 응용프로그램이 접근하는 것은 ring3
  - **커널**(알맹이, 핵심 이라는 뜻): OS가 CPU를 사용하는 모드
  - 응용프로그램~시스템콜: 사용자 영역, 시스템콜~하드웨어: 커널 영역
    - 커널 영역은 커널 모드에서 실행되는 코드들이 저장된 장소
  - 시스템 콜은 커널 모드로 실행, 커널 모드로 실행하려면 시스템 콜을 거쳐야 함: 응용프로그램이 함부로 전체 컴퓨터를 해치지 못하게 함
  - 프로그램 작동 과정
    - 응용 프로그램이 실행되어 OS 기능이 필요한 API를 호출(사용자 모드)
    - 시스템콜 호출되면서 **커널모드로 변경**
    - OS내부에서 해당 명령이 실행
    - 사용자모드로 변경되고 응용 프로그램으로 돌아가 계속 실행



## 2. 프로세스, 스케줄링

> 프로세스: 응용 프로그램
>
> 스케줄링: 시분할 시스템 등 여러 응용 프로그램을 CPU에 할당하는 방법

- 배치 처리 시스템: **자동으로** 순차 처리, 선입선출
  - 응답시간 느리고, 동시 실행/다중 사용자 지원이 되지 않음
- 시분할 시스템
  - 멀티태스킹: 단일 CPU에서 여러 응용프로그램이 동시에 **실행되는 것처럼** 보이도록 하는 시스템 -> 응답속도가 극히 빨라서 끊기는 것을 못 느낌
  - 멀티(병렬) 프로세싱: 여러 CPU가 하나의 프로그램을 병렬로 실행해서 속도 극대화
- **멀티 프로그래밍**
  - 프로그램 실행 중 입출력 이벤트 등 시간이 많이 걸리는 **blocking**이 발생하면 CPU가 놀게 되므로 다른 프로그램을 실행 - 비동기 논블로킹
    - 블로킹: [참고](https://sjh836.tistory.com/109)
    - 여기서는 계속 비동기 논블로킹 기준으로 얘기하고 있는듯?
- **프로세스**
  - 메모리에 올려져서 **실행 중인** 프로그램: OS로부터 시스템 자원을 할당받는 작업의 단위
    - 프로그램은 실행되기 전 상태의 명령어의 집합
  - 작업, task, job이라고도 함: 미묘한 차이가 있으나 혼용됨
- 프로세스의 상태(State)
  - new: 생성
  - **ready**: CPU에 넣으면 바로 실행이 가능한 상태
    - ready state queue
  - **running**: 실행 중, ready-running은 스케줄러가 배치(dispatch, interrupt)
    - running state queue
    - PC(Program Counter)가 현재 가리키고 있는 곳이랄까?
  - **blocked(ing)**: 특정 이벤트 발생 대기(입출력 등), **끝나면** ready로 변경
    - block state queue
    - 끝났는지는 누가 알려줌?: **interrupt**
      - interrupt: 프로세스를 중단시키는 기술
      - 선점형 스케줄러에서 필수적인 기술
      - 주요 인터럽트
        - 내부(software interrupt): ZeroDivision, 잘못된 인덱스, Overflow
        - 외부(hardware interrupt): 전원이상, 타이머, I/O
      - IDT(Interrupter Discriptor Table)에서 해당 인터럽트 주소를 찾아서 실행
        - 시스템 콜도 인터럽트: `0x80`
  - exit: 종료되면 프로세스가 가진 시스템 자원을 돌려놓음





### 2.2. 스케줄링 알고리즘

> CPU 버스트가 균일하지 않은 다양한 프로그램이 공존하므로 효율적으로 CPU를 사용하기 위해서 스케줄링 기법이 필요



- 어느 순서대로 프로세스를 실행시키는가?
  - 스케줄러: 프로세스 실행을 관리
  - No starvation, Fairness, Balance(모든 시스템을 바쁘게)를 목적으로 함
- 선점형/비선점형 스케줄러
  - 비선점형은 프로세스가 1. 자발적으로 blocking 상태가 되거나 2. 실행이 끝났을 때만 교체가 일어남: 응답시간이 길어질 수 있음
  - 선점형은 우선순위 기반으로, 적절한 time-slicing이 필요하며, I/O-bound-process는 CPU-bound process보다 높은 우선순위에 있어야 함
- 비선점 스케줄링
  - FIFO: CPU를 처음부터 끝까지 사용
    - 배치 처리 시스템
    - First Come First Served Scheduler
  - SJF(Shortest Job First)
    - 가장 실행시간이 짧은 프로세스부터 실행
    - 프로세스의 실행시간을 정확히 예측할 수는 없으므로 이상적임
    - 응답시간이 FIFO보다 짧음
- 선점 스케줄링
  - 우선순위 기반 스케줄러: 우선순위가 같을 경우 FCFS와 같음
    - 정적 우선순위: 프로세스 별로 미리 우선순위를 지정
    - 동적 우선순위: 스케줄러가 상황에 따라 우선순위를 변경
  - SRT(Shortest Remaining Time)
    - 최단 잔여시간인 프로세스를 먼저 할당: 선점형 SJF라고 할 수 있음
  - Round Robin 스케줄러
    - 기본적으로 FIFO로 동작하나, 특정 시간동안 프로세스가 끝나지 않으면 준비 큐(RoundRobin Ready Queue)로 넣어줌
    - time slice가 너무 작으면 context switch가 많고, 너무 크면 fcfs와 다를 바 없어짐

- **Context Switching**: 프로세스 교환
  - 이를 이해하려면 프로세스의 구조를 이해해야 함
  - 프로세스 구조
    - Stack: 임시 데이터 - 함수를 실행한 후 그 다음에 실행할 주소(RET), 함수 내 지역변수 및 인자
      - 버퍼, 변수, RBP(Base Point), RET(Return Address)로 구성됨
      - main내에서 sum을 불러오면 RET-RBP-변수c-버퍼-변수x-변수y-RET-RBP-버퍼 순으로 쌓이게 됨
        - 함수를 불러올 때는 해당 함수의 파라미터가 RET아래에 들어감
      - **Stack Overflow**: 스택 내에 공간이 모자라 데이터가 덮어씌워지는 경우가 있음. 이걸 악용해 RET 값을 원하는 값으로 변경해 권한을 얻고 공격하는 기법
    - Heap: 코드에서 **동적으로** 만들어지는 변수
      - 동적 할당: 입력되는 데이터에 맞게 기억공간을 확보하는 것
    - Data(BSS, Data): 초기화 안 된 전역변수(BSS), 초기화 된 전역변수(Data)
    - Code: 컴파일된 소스 코드
  - **Context**
    - 프로세스가 어떤 상태에서 수행되고 있는지 정확히 규명하기 위해 필요한 정보
    - 프로세스 주소 공간, 레지스터값(PC, SP), 커널에서 수행한 작업의 상태 등을 포함
      - PC(Program Counter)는 프로세스 내부에서 한줄씩 따라가는 포인터
      - SP(Stack Pointer)는 스택 내부의 포인터
    - 컨텍스트 스위치가 일어날 때, context를(PC, SP) **PCB**라는 저장공간에 저장해두고 다른 프로세스 실행
      - 프로세스는 운영체제에서 **PCB(process control block)**으로 표현됨
      - 프로세스 메타데이터(ID, register값, 스케줄링 정보, 메모리 사이즈) 저장, 프로세스가 생성될 때 PCB가 생성되고 프로세스 완료 시 제거됨
      - PCB는 메모리에 저장됨
    - 다시 실행할 때는 CPU내부 레지스터에 PCB를 불러와 덮어씌움
    - 컨텍스트 스위치는 어셈블리어로 작성됨: 각각의 CPU에 대해 작성
- 프로세스간 커뮤니케이션(InterProcess Communication)
  - 프로세스는 다른 프로세스 공간 접근 불가: 데이터/코드가 바뀌는 것을 막기 위해
  - 통신을 해야 하는가?
    - 여러 프로세스 동시 실행시 프로세스간 상태 확인 및 데이터 송수신 필요
    - fork()를 이용하여 똑같은 프로세스를 만들어 병렬처리하는 방법 등이 있음
  - 어떻게 하는가?
    - file을 이용하여 저장매체 공유하는 방법: 느리고, 실시간으로 업데이트 어려움
    - 커널 공간을 이용: 메세지 큐, 공유 메모리, 파이프, 시그널, 소켓 등
      - 프로세스들이 커널 공간은 공유하기 때문(자세한건 가상메모리 참고)



### 2.3. 스레드

> Light Weight Process: 소규모의 프로세스처럼 동작, CPU 이용의 기본 단위
>
> 프로세스 간에는 데이터 접근이 불가능하나 스레드는 프로세스 데이터 접근 가능 -> IPC  불필요

- 스레드 구조
  - 프로세스의 스택을 나누어 가짐: 각각의 **함수**라 생각하자
  - 각 스레드를 위한 PC와 SP가 존재
  - POSIX 스레드 API를 이용하여 구축 
- 멀티 태스킹과 스레드
  - 멀티태스킹: 다른 프로세스를 빠르게 바꾸며 동시에 실행되는 것처럼 함
  - 멀티 프로세싱: 여러 CPU가 하나의 프로세스를 병렬 실행해 속도를 향상
    - 어떻게? 스레드를 여러 개 만들어서 나누어주는 것
- 멀티 스레딩의 장단점
  - 장점
    - 응답성 향상: 기능을 나눠서 응답시간 단축
    - 자원 효율: 공유를 위한 추가적인 공간이 필요하지 않음
    - IPC가 필요 없고 스레드 간 통신이 간단함
    - 스레드 간 context switching은 캐시메모리를 비우지 않아도 되어 빠름
  - 단점
    - 한 스레드에 문제가 생기면 전체가 와장창
    - context switching이 많이 일어나 성능 저하: 이건 OS마다 다를 수 있는데 리눅스의 경우 스레드를 프로세스처럼 다루기 때문
      - 원래 이건 멀티 프로세스의 단점임
    - **동기화 이슈**
  - 파이썬과 멀티 스레딩
    - 기본적으로 Global Interpreter Lock 때문에 안 됨
      - 파이썬은 하나의 프로세스 안에 모든 자원의 lock을 글로벌하게 관리함
      - 따라서 계산 처리를 하는 작업은 한번의 하나의 스레드에서만 동작
      - 그러나 I/O작업을 실행하는 동안에는 다른 스레드가 cpu 동작을 할 수 있음
- **스레드 동기화**
  - 스레드 간 실행순서가 정해져 있지 않아 공유 자원 무결성에 문제가 생겨 비정상적인 동작이 있을 수 있음
    - 예) 각 스레드가 100만까지 센 다음에 합한다고 생각하자. 계산이 많아 중간에 타이머 이벤트로 context switching이 일어나서 전역변수를 읽어오지 않고 잘못된 값을 저장해 덧셈이 누락
  - 동기화 이슈는 lock을 걸어 해결할 수 있음: **mutual exclusion**
    - 공유 변수에 대해 동시 접근을 막는 것
    - 동시 실행을 막는 영역을 critical section이라 함
    - locking mechanism
      - Mutex: 임계 구역에 단일 스레드만 들어갈 수 있음
      - Semaphore: 여러 스레드가 들어가되 갯수를 제한함
  - 세마포어: 바쁜 대기
    - 한 스레드가 들어갈 때마다 S값을 1깎고 0이되면 대기시킴
    - 대기할 때 루프를 계속 돌기 때문에 CPU 성능 저하
    - S가 음수일 때 스케줄러가 스레드를 대기큐에 넣는 식으로 해결
  - 과도한 lock으로 인한 병목현상 발생 가능
    - 동기화 처리가 필요한 부분에만 synchronized
- **Deadlock**
  - 상호배제, 점유대기, 비선점, 순환대기 4가지가 성립되면 교착상태 발생 가능
  - 이를 회피하기 위해서는 조건 중 일부가 성립 안 되게 코드를 짜는 수밖에
- **Starvation**
  - 특정 프로세스의 우선순위가 낮아 자원을 계속 할당받지 못하는 상태
  - 우선순위를 변경하여 해결



## 3. 가상 메모리

> 프로세스에 충분한 메모리를 할당해주기 위해 메모리가 실제보다 많아보이게 함
>
> 예) 리눅스는 하나의 프로세스가 4GB이나 통상 8, 16정도

- 멀티 프로그래밍, 멀티 프로세싱을 위해 메모리가 상당히 많이 필요함

  - 그러나 매 순간마다 모든 메모리를 다 사용하는 것은 아님
  - 지금 사용하는 공간만 메모리에 넣어주는 식으로 동작: 가상 주소 도입

- 가상메모리 기본 아이디어

  - 프로세스는 가상 주소를 사용하고 실제 데이터를 읽고 쓸때 물리주소로 변경
  - 가상 주소 메모리 접근이 필요할 때 MMU(Memory Management Unit)가 빠르게 해당 주소를 물리주소값으로 변경

- 가상 메모리 메커니즘

- **페이징(paging) 시스템**

  - 크기가 동일한 페이지로 가상주소공간과 물리주소공간을 관리
  - 리눅스의 경우, 4KB 단위로 메모리를 쪼갬
  - 페이지 번호를 기반으로 가상주소-물리주소 매핑정보를 기록, 사용
  - PCB에 페이지 테이블(페이지 번호 기록) 구조를 담음
    - CPU 입장에서는 가상주소 참조 -> 페이지테이블 참조 -> 물리주소 참조
    - 주소만 담기에는 페이지가 큼: 가상주소는 (페이지, 인덱스)로 관리

  - 다중 단계 페이징 시스템
    - 페이지 정보를 단계를 나누어 생성
    - 페이징 시스템에서는 21비트에 페이지번호, 11비트 오프셋(인덱스) 할당했으나 실제로 사용되는 것이 그렇게 많지는 않으니 3~4단계로 나눠 디렉토리, 페이지 테이블 등으로 나눔
      - 4GB에 대해서 테이블을 다 만드는게 아니라 내가 필요한 부분만
  - TLB(Translation Lookaside Buffer)
    - 페이지 정보 캐시: 최근 변환된 물리주소 정보를 저장, 메인메모리 접근(페이지 테이블)하는 시간을 절약
  - 공유 메모리
    - 프로세스들이 동일한 물리 주소를 가리킬 수 있음(fork한 경우)
    - 프로세스 fork 시 4GB를 통으로 복사하는 것은 오래 걸리기 떄문에 그냥 물리메모리 주소만 복사
  - 요구 페이징
    - 모든 데이터를 메모리에 적재하는게 아니라 실행시 필요 데이터만 적재
    - **선행페이징**과 반대: 프로세스 실행 데이터를 미리 적재해 둠
  - **페이지 폴트** : 요구 페이징 메커니즘
    - 페이지가 실제 물리메모리에 없을 때 발생하는 인터럽트
    - 그러면 OS 해당 페이지를 물리메모리에 올려주고 페이지테이블 수정
    - 페이지 폴트가 일어나면 Storage에 접근해야 함: 굉장히 오래 걸림
    - 그럼 데이터를 어떻게 예측하여 메모리에 미리 올리는가?
  - 페이지 교체 알고리즘: 물리메모리가 다 차서 페이지 폴트가 날 때
    - FIFO: 가장 먼저 들어온 페이지를 내림
    - OPT: 앞으로 안 쓸 페이지를 예측(...)해서 내림, 물론 구현 불가
    - **LRU**: 가장 오래 전에 사용된 페이지를 내림
    - LFU: 가장 참조가 적게 된 페이지를 내림
    - NUR(Not Used Recently): 참조 비트, 수정 비트를 두어 참조도 수정도 안 이루어진 페이지를 우선적으로 내림
    - Thrashing: 페이지 교체가 과도하게 일어나 CPU가동률 저하

- **세그멘테이션** 기법

  - 가상메모리를 서로 **크기가 다른** 논리단위(segment)로 분할
  - 예) x86 리얼모드(부팅 시 사용)
  - 페이징과 비슷하게 `v = (s, d)`로 가상주소를 알아냄
  - **외부 단편화**가 발생할 수 있음
    - 원하는 연속된 크기의 메모리를 물리 메모리에 담을 수 없음
    - **내부 단편화**는 페이지 내부가 남아서 낭비되는 현상



## 4. 파일 시스템

> 운영체제가 저장매체에 파일을 쓰기 위한 자료구조/알고리즘

- 파일 시스템은 왜 만들어졌는가?
  - 비트로 관리하기엔 **오버헤드** 가 너무 큼 -> 블록 도입(4KB)
    - 오버헤드: 어떤 처리를 하기위해 필요한 총 시간
    - CPU사용, 메모리 사용 등이 과도하면 오버헤드 발생이라고 함
  - 블록 고유 번호 관리의 어려움으로 논리적 객체인 파일 도입
- 파일을 어떻게 효율적으로 저장하는가?
  - 외부 단편화 등으로 불연속해진 공간에 최대한 채우는 방법
    - 블록체인(그거아님): 블록을 linked list로 연결
    - 인덱스 블록: 블록체인의 느린 탐색 극복
- 파일 시스템 종류
  - 윈도우: FAT, FAT32, NTFS 블록 위치를 FAT이라는 자료구조에 기록
  - LINUX: ext2, ext3, ext4 인덱스 블록 기법의 일종인 **inode 방식** 사용
  - 동일한 시스템 콜(open)에 대해 다양한 파일시스템 지원이 필요
- inode 방식
  - 수퍼 블록(파일 시스템 정보), inode 블록(파일 정보), 데이터 블록으로 구성
  - 데이터에는 12개 블록을 저장할 수 있음
    - 48KB는 너무 작기 때문에 indirect block을 이용해 블록을 참조
      - direct  block pointer, single indirect pointer, double..



#### 부팅

- 부트 프로그램
  - 커널을 storage에서 특정 물리 메모리로 복사하고 커널의 처음 실행위치로 PC를 가져다 놓는 프로그램
  - 프로그램은 메모리에서 CPU에 가져가는건데 메모리가 비었음, 누가 함?
    - BIOS가 함: 컴퓨터 켜면 CPU가 ROM내의 BIOS 프로그램의 일부가 BIOS 프로그램을 메모리에 올림
    - 저장매체의 맨 앞(Master Boot Record)에 적힌 코드를 메모리에 로드
    - 파티션 테이블을 읽고 메인 파티션의 부트섹터를 읽음
    - 부트 코드 로드, 커널 이미지 주소를 알아내 이미지 로드, 커널 실행



## 5. 가상머신

> 하나의 하드웨어에 다수의 OS를 설치하고 개별 컴퓨터처럼 동작하도록 함

- 구조
  - 하드웨어 위의 가상머신이 자신이 하드웨어인 것처럼(에뮬레이트) 동작
- 종류
  - 타입1: VMM이 하드웨어에서 직접 구동 (Xen)
  - 타입2: VMM이 HOST OS 위에 설치됨 (VMWare)
- **Docker**
  - 가상머신이 하드웨어를 추상화한다면 도커는 커널을 추상화 함
  - 리눅스 기반이므로 리눅스 설치 후 그 위에서 구동
  - 실행환경을 통채로 백업 가능: 실무에 많이 사용됨
    - 프로그램 업데이트 -> Docker 이미지 작성 -> **Jenkins**로 배치잡 생성/실행
- JVM
  - 응용프로그램 레벨에서의 가상화: 엄밀하게 가상머신은 아님
  - CPU에 의존적이지 않음
- **가상 파일 시스템**
  - 디바이스 드라이버(입출력 장치)