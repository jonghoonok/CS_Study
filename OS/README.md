# OS

운영체제 기초부터 심화까지



참고서적

- 운영체제와 정보기술의 원리
  -  [이화여대 강의](http://www.kocw.net/home/search/kemView.do?kemId=1046323) : "운영체제" - 반효경
- Operating Systems: Three Easy Pieces



[TOC]

## **1. 운영체제란?**



운영체제의 정의

- 컴퓨터 하드웨어 바로 윗단에 설치되는 **소프트웨어**
  - 하드웨어만 있어서는 사용 불가: OS가 있어야만 컴퓨터 시스템이 구성
  - 하드웨어를 동작시키기 위해 필요한 기본 소프트웨어가 운영체제
    - 과거에는 프로그래밍 시 하드웨어의 동작을 일일이 정의해야 했으나 이런 부분을 운영체제로 넘기고 응용 프로그램 설계만 할 수 있게 됨



운영체제가 하는 일은 무엇인가?

- **시스템 자원**(CPU, 메모리, I/O device, 저장매체) 관리
  - 운영체제 기능의 핵심: 운영체제를 자원관리자(resource manager)라 부르기도 함
  - 각 프로그램이 CPU를 얼마나 사용해야 하는가?
  - 각 프로그램이 메모리의 어디에 얼마나 공간을 차지하는가?
  - 입력된 데이터를 어떤 프로그램이 사용하는가? 출력을 어떻게 하는가?
  - 어디에 어떻게 저장하는가?
- 사용자-컴퓨터 간 커뮤니케이션 지원
- 하드웨어와 **응용프로그램** 제어
  - 프로세스 관리, 램 관리, 파일 관리, 디스크 관리, 입출력 관리, 네트워킹/보안
  - 응용프로그램(Application)이란?
    - 소프트웨어에서 OS를 제외한 나머지
  - OS는 응용프로그램을 **실행**하고, **권한**을 관리함
    - 응용 프로그램이 요청하는 시스템 리소스를 효율적으로 분배



운영체제의 분류

- 작업처리 방식에 따른 분류
  - 일괄처리 방식(batch processing)
  - 시분할 방식
  - 실시간 운영체제
    - hard realtime system: 로켓, 원자로 제어 시스템
    - soft realtime system: 스트리밍 시스템
- 동시작업 지원 여부
  - single tasking: MS-DOS
  - multi tasking: UNIX, Windows
- 다중 사용자 동시 지원 여부
  - 단일 사용자용 운영체제: 클라이언트
  - 다중 사용자용 운영체제: 서버



### 1.1. OS의 역사

- 60년대 batch processing system 탄생
  - **운영체제의 출현**
  - 배치 처리 시스템: 여러 응용 프로그램을 등록해두면 순차적으로 일괄처리
- 60년대 후반 time sharing system, multi tasking 개념 탄생(구현x)
  - 시분할: 다중 사용자 지원 시 **컴퓨터 응답시간** 을 줄일 필요성에 따라 도입
    - [응답시간이란?](#스케줄링-성능-평가)
    - 시간을 잘게 분할해 프로그램을 교대로 실행: 쪼갤 수록 응답시간이 빨라짐
    - 입력의 결과가 바로 화면에 나타나므로 **대화형 시스템**이라고도 부름
  - **멀티태스킹**: CPU의 활용도 극대화
    - 여러 응용프로그램의 병렬 실행: 이것도 시분할을 이용
    - 멀티프로그래밍: 입출력 등 CPU **안 쓰는 시간에 다른 작업 실행**
- 70년대 **UNIX의 탄생**
  - 현대 운영체제 기술 확립(시분할, 멀티 태스킹)
  - C언어로 개발됨
    - 기존 어셈블리어는 메모리에 직접 할당하기 때문에 하드웨어가 달라지면 재코딩 필요
    - C언어 개발에 따라 범용적 소프트웨어 개발이 가능해졌고 이를 기반으로 UNIX도 개발
- 80년대 PC의 탄생
  - 터미널 환경 CLI -> GUI(84' Macintosh)
- 90년대 
  - 응용프로그램(엑셀, 워드) 보급과 Windows의 대중화
    - 엑셀을 위해 windows를 사고 위닝을 위해 PS를 삼: killer application
  - 네트워크 기술 발전: www
  - 오픈 소스 운동 활성화: **LINUX**
- 2000년 이후
  - 오픈 소스 활성화: LINUX, Apache, MySQL, Android, 딥러닝, IoT 관련
  - 가상 머신(한 컴퓨터에 여러 OS 설치), 대용량 병렬 처리 활성화(멀티 코어)



### 1.2. OS 개요



#### 운영체제의 구조

> 사용자 - 응용프로그램/쉘 - API - 시스템콜 - OS - hardware
>
> 플랫폼, 쉘, 컴파일러 이런애들을 시스템 소프트웨어라고 함

![os structure](https://s3.ap-northeast-2.amazonaws.com/static.gracieuxyh.dev/os/os-structure-1.png)

- 사용자 인터페이스
  - **쉘**: 사용자가 OS기능과 서비스를 조작할 수 있게 인터페이스 제공
  - 쉘은 CLI(터미널 환경)와 GUI환경 두 종류로 분류됨
- 라이브러리, 응용프로그램 인터페이스(API)
  - 함수의 집합: 각 "언어 별"로 OS조작하는 함수 존재(`open()` 등)
  - 함수들을 묶어서 라이브러리 형태가 제공됨(C library 등)
    - 리눅스는 어차피 C로 만들었기 때문에 시스템 콜을 직접 사용할 수도 있으나 범용성을 위해 C API가 사용됨
    - 쉘도 응용프로그램으로, 운영체제가 제공하는 API 이용함
- **시스템 콜** or 시스템 호출 인터페이스
  - OS의 각 기능을 사용할 수 있도록 제공되는 함수
    - 응용 프로그램은 고급언어로 개발되어 직접 시스템 콜을 사용할 수 없음
  - API는 내부에서 시스템 콜을 호출
  - 시스템 콜을 정의하는 문서 **POSIX**
    - `open()`, `close()` 등 시스템 콜들을 서로 다른 유닉스 OS에서 사용할 수 있도록 공통 API를 정리한 규격
    - POSIX API, 윈도우 API를 기본으로 각각의 OS에 대한 시스템 콜을 개발함



CPU Protection Rings

![rings](https://s3.ap-northeast-2.amazonaws.com/static.gracieuxyh.dev/os/cpu-protection-rings.png)

- Intel 기준 4개의 링으로 구성되며 핵심인 ring0 커널을 둘러싸고 있음
  - ring의 **숫자가 작아질수록 커널에 가까워지면서 권한도 커짐**
  - 응용프로그램이 접근하는 것은 ring3이고 ring1, 2는 거의 사용되지 않음
    - 대부분의 운영체제는 0, 3만 이용하는 Dual Mode System
- ARMv8의 경우 7가지 모드 존재!



CPU의 권한 모드

![mode](https://s3.ap-northeast-2.amazonaws.com/static.gracieuxyh.dev/os/dual-mode-converting.png)

- 사용자 모드: 일반 사용
  - 제한적인 명령만을 수행할 수 있음
  - **다른 프로그램의 메모리 영역 등을 침범하지 않게**끔 CPU 내부에 **mode bit**를 두어 0이면 커널모드로서 모든 명령 수행, 1이면 제한된 명령만 수행할 수있게 함
- **커널 모드**: 특권 명령어 실행 및 원하는 작업 수행을 위한 자원 접근 가능 모드
  - 커널이란?
    - 알맹이, 핵심 이라는 뜻
    - **메모리에 상주**하는 OS의 부분: 운영체제 중 항상 필요한 부분
    - 보안, 리소스 관리, 추상화 등의 기능을 함
    - 대부분의 운영체제는 커널 위에 여러 개의 층을 올린 것
    - 커널모드는 응용프로그램이 아니라 **OS가 CPU를 사용**하는 모드
  - 시스템 콜은 커널 모드로 실행
    - **커널 모드로 실행하려면 시스템 콜을 거쳐야 함**
    - 응용프로그램이 함부로 전체 컴퓨터를 해치는 것을 방지

- 사용자영역, 커널 영역
  - 사용자 영역은 응용프로그램부터 시스템콜
  - 커널 영역은 시스템콜부터 하드웨어까지
    - 커널 모드에서 실행되는 코드들이 저장된 장소
- 프로그램 작동 과정
  - 응용 프로그램이 실행되어 OS 기능이 필요한 API를 호출(사용자 모드)
  - 시스템콜 호출되면서 **커널모드로 변경**
  - OS내부에서 해당 명령이 실행
  - 사용자모드로 변경되고 응용 프로그램으로 돌아가 계속 실행



컴퓨터 시스템의 동작 원리

![아키텍처](https://media.vlpt.us/images/min1378/post/8382edfe-5301-44f3-a85e-e80ce6598329/%EC%8B%9C%EC%8A%A4%ED%85%9C%EA%B5%AC%EC%A1%B0-1.png)

- 컴퓨터 시스템의 구조
  - 내부장치: CPU, 메모리
  - 외부장치: 디스크, 입출력장치(키보드, 프린터, 모니터), 네트워크 장치 등 
- 동작의 흐름
  - 외부장치에서 내부장치로 데이터를 읽어오고 연산 수행 후 외부로 내보냄
  - **컨트롤러**: 각 하드웨어를 제어하는 작은 CPU
    - 입출력 시 각 컨트롤러는 장치를 제어하여 데이터를 **로컬 버퍼**에 저장
    - 입력의 경우, 로컬 버퍼에 저장이 끝나면 컨트롤러가 메인 CPU에 인터럽트를 발생시켜 데이터를 메모리로 송출
  - **DMA**: CPU이외에 메모리 접근이 가능한 컨트롤러
    - 입출력 장치들의 너무 잦은 인터럽트로(byte 단위) 인한 비효율성 극복
    - 입출력 장치 로컬버퍼에서 메모리로 데이터를 읽어오는 작업을 CPU 대신 수행
    - 데이터를 **블록 단위로** 메모리에 저장한 후 CPU에 인터럽트 발생시킴



## **2. CPU 관리**

> 어떠한 프로세스에 CPU를 할당해 작업을 처리할 것인가?



### 2.1. 프로세스

프로세스란?

- 실행 중인 프로그램 *program in execution*

  - 프로그램이 **메모리에 올라가서 실행되기 시작하면** 프로세스가 됨

    ![load](https://media.vlpt.us/images/min1378/post/3936e685-bc35-4069-87ed-665e05754f6d/%EC%8B%9C%EC%8A%A4%ED%85%9C%EA%B5%AC%EC%A1%B02-3.png)

    - 프로그램은 실행되기 전 상태의 명령어의 집합
    - 작업, task, job이라고도 함: 미묘한 차이가 있으나 혼용됨
    - 메모리에 올라가면 **독자적인 주소공간**이 생김
      - 우선 가상 메모리에 올라가고 필요 시 물리 메모리에 적재 됨
      - 자세한 내용은 [가상 메모리](#3.2.-가상-메모리)

  - OS로부터 **시스템 자원을 할당받는 작업의 단위**

- 프로세스의 실행 상태

  - 하나의 프로세스 실행 중에는 자신의 코드와 **커널의 코드도 같이 실행됨**
  - user mode running: 자신의 주소 공간에 정의된 코드를 실행
  - kernel mode running: 커널모드에서의 실행 상태
    - **커널이 프로세스가 하는 일을 대행**하는 상태
    - 입출력 시스템 콜 등을 통해 커널의 함수를 호출하여 실행

- 다중 프로세스

  - **멀티태스킹**
    - 단일 CPU에서 여러 프로세스가 동시에 **실행되는 것처럼** 보이도록 하는 시스템
    - 시분할 시스템 이용: 응답속도가 극히 빨라서 끊기는 것을 못 느낌
  - 멀티(병렬) 프로세싱
    - 여러 CPU가 여러 프로그램을 병렬로 실행해서 속도 극대화
  - 멀티 프로그래밍
    - 단일 CPU에서 여러 프로그램(프로세서)이 동시에 실행될 수 있도록 하는 것
    - 프로그램 실행 중 **blocking**이 발생하면 다른 프로그램을 실행하여 구현: 엄밀히 말하면 동시 실행은 아님



프로세스의 상태(State)

![state](https://jhi93.github.io/assets/img/os/ProcessState2.png)



- 프로세스의 상태는 크게 실행(running), 준비(ready), 봉쇄(blocked)
  - 하나의 프로세서에서 현재 **실행 중인 프로세스는 1개 뿐**
  - CPU를 효율적으로 이용하기 위해 프로세스에 상태를 부여해서 관리
  - 상태 관리는 커널의 데이터 영역에 다양한 queue를 두어서 관리함
    - ready queue: 준비 상태에 있는 프로세스를 담는 큐
    - device queue: 각 장치(자원)에 동시 접근하는 것을 막기 위해 접근 순서 부여
    - job queue: 시스템 내의 모든 프로세스를 관리, 프로세스의 전체 집합
    - 각각의 큐는 각 프로세스의 **PCB를 연결 리스트 형태로 관리**
- **new**: 생성
  - 프로세스를 위한 자료구조는 생성되었지만 메모리 획득은 승인받지 못한 상태
- **ready**: CPU에 넣으면 바로 실행이 가능한 상태
  - **CPU dispatch**: 스케줄러가 ready state queue의 선두에 있는 프로세스에 CPU 제어권을 넘겨주는 것
  - 준비 큐의 순서를 결정하는 것이 [CPU 스케줄링](#2.2.-스케줄링)
- **running**: 실행 중인 프로세스
  - running state queue
  - CPU할당 시간이 끝나면 타이머 인터럽트가 발생
  - 실행 중인 프로세스는 **문맥을(context) 저장**하여 준비 상태로 내림
  - 새로운 프로세스를 선택하여 실행
- **blocked(ing)**: 특정 이벤트 발생 대기(입출력 등)
  - block state queue
  - 입출력 이벤트가 발생하면 CPU를 반환한 뒤 봉쇄 상태 진입
    - 진입하지 않는 경우도 있음: [I/O 모델](#I/O 모델) 참고
  - 입출력 이벤트가 끝나면 컨트롤러에 의한 **interrupt**가 발생
  - 실행중이던 다른 프로세스가 **커널모드 실행 상태** 진입하여 인터럽트 처리루틴 수행
  - 봉쇄된 프로세스는 준비 상태 진입
  - 인터럽트 당한 프로세스가 다시 실행되거나 입출력 프로세스가 실행상태로 진입 
- **terminated**: 종료되면 프로세스가 가진 시스템 자원을 돌려놓음
  - 프로세스가 종료되었으나 아직 관련 자료구조를 완전히 정리하지 못한 상태
- **swap**: 프로세스가 메모리를 당분간 획득할 가능성이 없을 때(봉쇄) 디스크로 내림



프로세스 문맥 교환(context switch)

- 하나의 프로세스가 **다른 프로세스로** CPU 제어권을 넘기는 과정

  1. 인터럽트가 발생

  2. 원래 수행 중이던 프로세스의 **문맥**을 저장하고 새로운 프로세스의 문맥을 세팅

  - 커널모드로 전환될 때도 PCB에 문맥을 저장하지만 다른 프로세스로 변경되는 것은 아니기 때문에 이는 문맥교환이라 하지 않고 **모드 변경**이라 함
  - 문맥 교환이 모드 변경보다 훨씬 오버헤드가 큼

- 문맥: 프로세스가 어떤 상태에서 수행되고 있는지 정확히 규명하기 위해 필요한 정보

  - 프로세스 주소 공간, 레지스터값(PC, SP), 커널에서 수행한 작업의 상태 등을 포함
    - PC(Program Counter)는 프로세스 내부에서 코드를 한줄씩 따라가는 포인터
    - SP(Stack Pointer)는 스택 내부의 포인터
  - 컨텍스트 스위치가 일어날 때, **dispatcher**가 context를(PC, SP) 해당 프로세스의 **PCB**에 저장해두고 다른 프로세스(준비 큐의 제일 앞에 있는 것) 실행
    - 디스패처: 새롭게 선택된 프로세스가 CPU를 할당받을 수 있게 하는 OS의 코드
    - dispatch latency: 프로세스 정지부터 다른 프로세스레게 CPU를 전달하기 까지의 시간
      - 디스패치 지연시간의 대부분은 문맥교환 오버헤드
  - 다시 실행할 때는 CPU내부 레지스터에 PCB를 불러와 덮어씌움
  - 컨텍스트 스위치는 어셈블리어로 작성됨: 각각의 CPU 구조에 따라 작성됨



프로세스의 구조

![process memory](https://gabrieletolomei.files.wordpress.com/2013/10/program_in_memory2.png)

- 프로세스는 UNIX 기준 4GB가 메모리에 적재되며 커널 영역과 사용자 영역으로 나뉨
- 사용자 영역은 다시 Stack, Heap, Data, Code로 나뉨
  - **Stack**: 임시 데이터
    - 버퍼, 함수 내 지역 변수, 인자, RBP(Base Point), RET(Return Address, 함수 실행 이후에 돌아갈 주소) 등으로 구성됨
    - 예) main에서 sum을 불러오면 RET-RBP-변수c-버퍼-변수x-변수y-RET-RBP-버퍼 순으로 쌓이게 됨
      - 함수를 불러올 때는 해당 함수의 파라미터가 RET아래에 들어감
    - **Stack Overflow**: 스택 내에 공간이 모자라 데이터가 덮어씌워지는 경우가 있음. 이걸 악용해 RET 값을 원하는 값으로 변경해 권한을 얻고 공격하는 기법
  - **Heap**: 코드에서 **동적으로** 만들어지는 변수
    - 동적 할당: 입력되는 데이터에 맞게 기억공간을 확보하는 것
  - **Data(BSS, Data)**: 초기화 안 된 전역변수(BSS), 초기화 된 전역변수(Data)
  - **Code**: 컴파일된 소스 코드



PCB (Process Control Block)

- 프로세스 관리를 위해 **각 프로세스 별로 유지하는 정보들을 담는 커널 내의 자료구조**
  - 프로세스 메타데이터 저장
  - 프로세스 상태, ID, register값, PC값, 스케줄링 정보, 메모리 관리 정보, 자원 사용 정보, 입출력 상태 정보
- 프로세스가 생성될 때 PCB가 생성되고 프로세스 완료 시 제거됨
- PCB는 **메모리에 저장**됨



프로세스 생성

- 프로세스는 다른 프로세스를 복제함으로써 생성됨
  - 생성된 프로세스는 **자식 프로세스**, 생성한 프로세스는 **부모 프로세스**
  - 운영체제는 부팅 후 최초의 프로세스만을 직접 생성함
- 프로세스의 수행모델
  - 부모 자식이 공존하며 수행: CPU를 획득하기 위해 자식과 부모가 경쟁함
  - 자식이 terminate될때까지 부모가 `wait()`하는 모델
    - 자식 프로세스가 종료되면 부모 프로세스는 준비 큐에 재진입
- 생성 과정
  - `fork()` 시스템 콜을 통해 자신을 복제
  - ID와 fork()의 리턴값을 제외하고 모든 것이 똑같은 자식 프로세스 생성
    - `exec()` 시스템 콜을 통해 새로운 프로그램을 덮어씌워 다른 프로그램을 수행시킴
- 프로세스의 종료
  - 프로세스를 **종료하기 위해서는 모든 후손 프로세스들을 종료해야** 함
  - 자발적 종료
    - instruction을 모두 수행한 후 시스템 콜 `exit()`을 통해 운영체제에 종료를 통보
    - 운영체제가 프로세스의 자원을 회수하고 정리
    - exit은 개발자가 넣지 않아도 컴파일러가 자동으로 삽입함
  - 비자발적 종료
    - 부모 프로세스가 `abort()`를 통해 자식 프로세스를 강제로 종료시킴
    - 자식 프로세스가 한계치 이상의 자원을 요구하거나, 작업이 필요하지 않거나, 부모 프로세스가 종료되는 경우
    - 로그아웃 이후에도 수행시켜야 하는 프로그램의 경우 해당 프로세스를 로그아웃 후에도 존재하는 시스템 프로세스의 자식으로 이양시키는 절차가 필요함



프로세스 간 협력

- 프로세스는 원칙적으로 다른 프로세스의 주소 공간을 참조할 수 없음
  - 보안: 데이터/코드가 바뀌는 것을 막기 위해
  - 그러나 프로세스에게도 **스레드**와 같이 서로 정보를 주고 받는 것이 필요
    - 여러 프로세스 동시 실행시 **프로세스간 상태 확인 및 데이터 송수신 필요**
    - `fork()`를 이용하여 똑같은 프로세스를 만들어 병렬처리하거나 **IPC** 이용
- **Inter Process Communication**
  - 프로세스 간의 통신과 **동기화**를 이루기 위한 메커니즘
  - 메시지 전달 방식
    - 시스템 콜을 이용해 **커널을 매개로 데이터 교환**
    - 커뮤니케이션 링크를 이용하고, 공유 데이터를 사용하지 않음
    - 파이프를 이용한 직접통신, 메일박스(소켓)를 이용한 간접통신이 있음
    - 메세지 큐, 파이프, 시그널, 소켓 ???
    - file을 이용하여 저장매체 공유하는 방법: 느리고, 실시간으로 업데이트 어려움?????
  - 공유 메모리 방식
    - 프로세스들이 주소 공간의 일부를 공유
    - 서로 다른 프로세스는 독자적 주소 공간을 가지나 **공유메모리 영역에 대해서는 동일한 물리적 메모리 주소로 매핑됨**
    - 동기화 문제 발생 가능
- **동기화 문제**란?
  - **공유 자원 무결성**에 문제가 생겨 비정상적인 동작이 발생하는 것
  - 예) 각 스레드가 100만까지 센 다음에 합한다고 생각하자. 계산이 많아 중간에 타이머 이벤트로 context switching이 일어나서 전역변수를 읽어오지 않고 잘못된 값을 저장해 덧셈이 누락



#### 스레드

> Light Weight Process: 소규모의 프로세스처럼 동작, CPU 이용의 기본 단위
>
> 스레드는 프로세스와 달리 서로 간에 자원을 공유함: IPC  불필요



스레드란 무엇인가?

- 프로세스 내부의 **CPU 수행 단위**
  - 프로세스 내부에 이 단위가 여러 개 있을 때를 각각 스레드라 함
    - 예) 웹브라우저는 웹페이지를 로딩할 때 여러 스레드를 이용해 한 스레드가 I/O작업을 하는 중에 다른 스레드가 이미 읽어온 페이지를 로딩하여 응답성을 향상함
  - 전통적인 heavyweight process는 하나의 스레드를 가진 task라 볼 수 있음
- 스레드 구조
  - 프로세스의 스택을 나누어 가짐: 각각의 **함수**라 생각할 수 있음
  - 스레드는 **PCB도 공유**함
    - 스레드 별 PC와 레지스터 값들이 존재하여 **CPU가 코드의 어느 부분을 수행하고 있는가** 별도로 관리하여 CPU 수행 단위를 쪼갬
    - 나머지 부분은(프로세스 ID, 메모리 관리 정보 등) 공유

![tcb](https://blog.kakaocdn.net/dn/sxO0J/btqEwQ5PbRD/krWKDTE60qcaJpksIFcAy1/img.jpg)



멀티 태스킹과 스레드

- 멀티 프로세싱: 여러 CPU가 **여러 프로세스를 동시 실행**해 속도를 향상

- 멀티 스레딩: 스레드를 여러 개 만들어서 **한 프로세스를 병렬 실행** 

  - 장점
    - 응답성 향상: 기능을 나눠서 응답시간 단축
    - 자원 효율: 공유를 위한 추가적인 공간이 필요하지 않음
    - IPC가 필요 없고 스레드 간 통신이 간단함
    - 스레드 간 context switching은 캐시메모리를 비우지 않아도 되어 빠름

  - 단점
    - **한 스레드가 abort되면 전체가 죽음**
    - context switching이 많이 일어나 성능 저하
      - OS마다 다를 수 있는데 리눅스는 스레드를 프로세스처럼 다루기 때문
      - 원래 이건 멀티 태스킹의 단점임
      - 물론 프로세스의 context switching보다는 부하 적음
    - 공유자원을 보호하기 어려움: **동기화 이슈**
    - 스레드 간의 실행 순서를 예측할 수 없어 디버깅이 어려움

- 파이썬과 멀티 스레딩

  - 기본적으로 Global Interpreter Lock 때문에 안 됨
    - 파이썬은 하나의 프로세스 안에 모든 자원의 lock을 글로벌하게 관리함
    - 따라서 계산 처리를 하는 작업은 한번의 하나의 스레드에서만 동작
    - 그러나 I/O작업을 실행하는 동안에는 다른 스레드가 cpu 동작을 할 수 있음



**스레드 동기화**

- 동기화 이슈는 **lock**을 걸어 해결할 수 있음: **mutual exclusion**
  - 공유 변수에 대해 동시 접근을 막는 것
  - 동시 실행을 막는 영역을 **critical section**이라 함
- locking mechanism
  - **Mutex**(mutual exclusion): 임계 구역에 단일 스레드만 들어갈 수 있음
    - Lock을 소지하고 있는 스레드만 들어갈 수 있음
  - **Semaphore**: 여러 스레드가 들어가되 갯수를 제한함(바쁜 대기)
    - 한 스레드가 들어갈 때마다 S값을 1깎고 0이되면 대기시킴
    - **대기할 때 루프를 계속** 돌기 때문에 CPU 성능 저하
    - S가 음수일 때 스케줄러가 스레드를 대기큐에 넣는 식으로 해결
- lock의 문제점
  - 과도한 lock으로 인한 **병목현상 발생 가능**
    - 동기화 처리가 필요한 부분에만 synchronized
  - **Deadlock** 
    - 교착상태: 스레드 간에 대기 상태가 종료되지 않아 무한정 대기하는 것
    - 상호배제, 점유대기, 비선점, 순환대기 4가지 발생 조건이 성립되면 교착상태 발생 가능
    - 예방: 조건 중 일부가 성립 안 되게 코드를 짜는 수밖에 없음
    - 회피: 발생 조건은 그냥 두고, **은행원 알고리즘**(자원 할당 전에 할당 가능한지 판단) 등으로 회피 
    - 탐지&회복: 교착이 발생하면 탐지한 후 회복(껐다가 다시 켠다)
    - 무시: 발생확률이 낮다면 그냥 무시함
  - **Starvation**
    - 특정 프로세스의 우선순위가 낮아 자원을 계속 할당받지 못하는 상태
    - **우선순위를 변경**하여 해결



### 2.2. 스케줄링

> **CPU 버스트**가 균일하지 않은 다양한 프로그램이 공존하므로 효율적으로 CPU를 사용하기 위해서 스케줄링 기법이 필요



스케줄러란?

- **어떤 프로세스에게 자원을 할당할지** 결정하는 커널의 코드
- 스케줄러의 목적
  - No starvation, Fairness, Balance(모든 시스템을 바쁘게)
- **장기 스케줄러(job scheduler)**: 어떤 프로세스를 준비 큐에 넣을 것인가?
  - 시작 상태 프로세스 중 어떤 프로세스를 준비 큐에 넣을지 결정
  - 메모리에 올라가 있는 프로세스의 수 결정
  - 현대에는 필요 없어졌고 중기 스케줄러가 대신에 **swap out**을 수행함
    - 프로세스가 지나치게 많아져 프로세스 당 메모리 양이 적은 경우 수행
    - 봉쇄 상태인 프로세서를 우선적으로 스왑 아웃
    - 입출력 종료 등 봉쇄 이유가 없어지면 suspended ready로 전환되고 이후 swap in 됨
- **단기 스케줄러**: 준비 큐의 어떤 프로세스를 실행할 것인가?
  - 스케줄러가 호출되는 경우
    - 타이머 인터럽트 발생
    - I/O 요청
      - 실행 중인 프로세스가 봉쇄되는 경우
      - I/O작업이 종료되어 봉쇄 상태에 있던 프로세스가 준비 상태로 바뀌는 경우
    - 실행 중이던 프로세스의 종료
  - 스케줄링 방식
    - 비선점형: 프로세스가 **스스로 CPU를 반납하기 전까지 뺏기지 않는 것**
      - 프로세스가 자발적으로 blocking 상태가 되거나 실행이 끝났을 때 교체
      - 응답시간이 길어질 수 있음
    - 선점형: 프로세스가 CPU를 사용 중에 강제로 뺏을 수 있는 방식
      - 타이머 인터럽트, I/O 종료 후 문맥교환에 의해 I/O 완료된 프로세스에게 CPU 할당
      - 우선순위 기반, 적절한 time-slicing이 필요하며, I/O-bound-process는 CPU-bound process보다 높은 우선순위에 있어야 함



CPU버스트(burst)란?

- 프로그램이 I/O를 한번 수행하고 다음번 I/O수행까지 **직접 CPU를 갖고 명령을 수행하는 작업**

  - 커널이 I/O 작업을 수행하는 단계는 I/O 버스트라고 함

- CPU 버스트에서 수행하는 명령: **일반 명령**(아키텍처 참고)

  - CPU 내에서 수행하는 명령
    - Add 명령: 레지스터에 있는 두 값을 더해 레지스터에 더함
  - 메모리 접근을 수행하는 명령
    - Load 명령: 읽기
    - Store 명령: 쓰기
  - I/O 명령은 **특권 명령**으로 커널을 통해 서비스를 대행함

- CPU 버스트와 I/O 버스트의 비율에 따른 프로세스의 분류

  ![burst](https://media.vlpt.us/images/suuhyeony/post/c6a5f803-1704-4ab6-9634-c2d9c39bfd58/CPU%20burst%20time2.png)

  - CPU 버스트가 많음: CPU bound process
  - I/O 버스트가 많음: I/O bound process
    - 대화형 프로그램이 이에 해당됨
    - **I/O bound process에게 우선적으로 CPU를 할당하는 것이 목표**



#### 스케줄링 알고리즘



비선점 스케줄링

- **FIFO**: CPU를 처음부터 끝까지 사용

  - First Come First Served Scheduler 라고도 함
  - 먼저 도착한 작업의 성격에 따라 평균 대기시간이 크게 달라짐
    - CPU 버스트가 긴 프로세스가 먼저 도착하면 길어지고, 반대는 짧아짐
    - 프로세스 간 **대기시간 및 소요시간의 편차가 커지고 응답시간이 길어짐**

- **SJF**(Shortest Job First)

  - 가장 실행시간이 짧은 프로세스부터 실행

  - 프로세스의 실행시간을 정확히 예측할 수는 없으므로 이상적임

    - **과거의 CPU 버스트 시간을 통해 예측**을 수행함

    - $$
      T_{n+1} = \alpha t_n + (1-\alpha)T_n
      $$

    - T는 예측 시간, t는 실제 시간, alpha는 예측 계수로 0과 1 사이의 값을 가짐

    - 반복하여 대입하면 오래된 과거일수록 영향력이 작아짐

  - 응답시간이 FIFO보다 짧음

  - **starvation**이 발생할 수 있음



선점 스케줄링

- 우선순위 기반 스케줄러
  - 정적 우선순위: 프로세스 별로 미리 우선순위를 지정
  - 동적 우선순위: 스케줄러가 상황에 따라 우선순위를 변경
  - 무엇을 기준으로 우선순위를 매기는가?
    - CPU 버스트 시간: SJF와 같음
    - 모든 프로세스의 우선순위 동등: FCFS와 같음
  - 기아 현상의 극복
    - **aging** 도입: 대기 시간이 길어지면 우선순위 상향
- SRTF(Shortest Remaining Time First)
  - 최단 잔여시간인 프로세스를 먼저 할당
  - SJF를 선점형으로 구현하면 SRTF가 됨
- Round Robin 스케줄러
  - 기본적으로 FIFO로 동작하나, **특정 시간동안 프로세스가 끝나지 않으면 준비 큐**(RoundRobin Ready Queue)로 넣어줌
    - **할당 시간**(time quantum): 한 번에 CPU를 연속으로 사용할 수 있는 최대시간
    - CPU 버스트가 긴 프로세스에도 할당이 되므로 **공정한 스케줄링**이라 할 수 있음
    - 응답시간은 짧으나 평균 대기시간, 소요시간은 FCFS 대비 길어짐
  - time slice가 너무 작으면 context switch가 많고, 너무 크면 FCFS와 다를 바 없어짐
    - 일반적으로 수십 ms 정도로 설정함
    - 대화형 프로세스에서 끊김을 느낄 수 없는 정도



멀티 레벨 큐

- 준비 큐를 여러 개로 분할하여 관리하는 것
  - 성격이 다른 프로세스를 별도로 관리
  - foreground queue: 대화형 작업, Round Robin
  - backgound queue: 계산 위주의 작업, FCFS
- **큐 자체에 대한 스케줄링** 필요
  - 고정 우선순위 방식: 전위 큐에 우선적으로 CPU 할당
  - 타임 슬라이스: 각 큐에 CPU 시간 할당하는 비율을 정해 **기아 현상 해소**



멀티레벨 피드백 큐

![feedback queue](https://2.bp.blogspot.com/-iMfnvJQ7a6E/WwGBqKeB1tI/AAAAAAAAAUs/xdfHATAspXwazN_B1fvNdPaa1_rTSbQcwCLcBGAs/s1600/multilevel%2Bfeedback%2Bqueue%2Bscheduling%2Balgorithm.PNG)

- 멀티레벨 큐에서 프로세스가 다른 큐로 이동할 수 있게 한 방식 
  - 큐 별로 우선순위를 부여함
  - 할당 시간이 짧은 **상위 큐에서 작업이 끝나지 않으면 하위 큐로 이동**
    - 계산 위주의 프로세스라고 판단하는 것
  - 하위 큐에서 오래 기다리게 되면 상위 큐로 올려서 CPU 할당
    - 기아 문제 해결



기타 스케줄링

- 다중처리기 스케줄링 multi-processor scheduling
  - CPU가 여러 개인 시스템(multi-processor system)에서 스케줄링을 하는 방법
  - 미용실 예약과 비슷함: 도착한 순서대로 하기도 하고 특정 디자이너의 예약도 존재
  - 대칭형 다중처리
    - 각 CPU가 알아서 스케줄링
  - 비대칭형 다중처리
    - 하나의 CPU가 다른 CPU들의 스케줄링을 제어
- 실시간 스케줄링
  - **데드라인** 존재: 정해진 시간 안에 반드시 작업을 완료해야 함
    - 미사일 발사, 원자로 제어, 실시간 스트리밍
  - EDF(Earlist Deadline First) 스케줄링
    - 데드라인이 얼마 남지 않은 요청을 먼저 처리



스케줄링 성능 평가

- 시스템 관점
  - CPU 이용률
    - 전체 시간 중 **CPU가 일을 한 시간의 비율**
    - CPU가 idle상태에 있는 시간을 최소화하는 것이 목표
  - 처리량(throughput)
    - 주어진 시간 동안 준비 큐에서 기다리고 있는 프로세스 중 **몇 개를 끝냈는지**
    - CPU 버스트가 짧은 프로세스에 우선적으로 할당하는 것이 유리
- 사용자 관점
  - 소요시간 turnaround time
    - 프로세스가 **CPU를 요청한 시점부터 CPU버스트가 끝날 때까지** 걸린 시간
    - 준비 큐에서 기다린 시간 + 실제 사용한 시간의 합
    - I/O로 블록된 시간은 계산하지 않음
  - 대기시간 waiting time
    - **CPU버스트 중 프로세스가 준비 큐에서 기다린 시간**의 합
    - 시분할 시스템에서는 한 번의 CPU버스트 중에도 준비 큐에서 여러 번 기다릴 수 있음
  - 응답시간 response time
    - 준비 큐에 들어온 이후 처음으로 CPU를 획득할 때까지 기다린 시간
    - **타이머 인터럽트가 빈번히 발생할수록 짧아짐**
    - 대화형 시스템에 적합한 성능 척도

- 성능 평가 방법
  - queuing model
    - 이론가들이 주로 수행
    - **확률분포**를 통해 프로세스의 도착률과 CPU 처리율을 input으로 계산 수행
  - simulation
    - **가상으로 CPU 스케줄링 프로그램 작성** 후 프로그램의 CPU 요청을 input으로 계산
    - 입력값은 가상 또는 실제 시스템에서 추출한 입력값인 **trace**를 이용
  - implementation & measurement
    - 구현가들이 주로 수행
    - **커널의 스케줄링 코드를 수정**하여 동일한 프로그램에 대해 원래 커널과 비교



### 2.3. 주변장치, I/O장치 관리

> 인터럽트를 이용하여 관리



인터럽트란?

- 하드웨어나 소프트웨어에서 CPU가 필요할 때 이를 알려 요청하는 수단
  - 프로세스를 중단하는 기술로 특히 선점형 스케줄러에서 필수적
- CPU는 **명령 하나를 수행할 때마다 인터럽트가 발생했는지 확인**
  - 명령 instruction 옆에 인터럽트 라인 interrupt line 이 있음
- 현대 컴퓨터 시스템에서 **OS는 인터럽트가 발생할 때만 실행됨**
  - CPU는 정상 상태에서 항상 어플리케이션에 의해서만 실행
  - OS는 인터럽트가 발생했을 때만 CPU의 제어권을 획득: 커널 모드



인터럽트의 분류

- **하드웨어 인터럽트**
  - 통상적으로 일컫는 인터럽트: 각 장치 컨트롤러들이 CPU가 필요할 때 통보
  - 하드웨어 장치(컨트롤러 등)가 CPU의 인터럽트 라인을 세팅함
  - 전원이상, 타이머, I/O 등
- **소프트웨어 인터럽트**
  - 소프트웨어가 CPU의 인터럽트 라인을 세팅함
  - 예외상황: 비정상적 작업이나 권한 없는 작업을 시도할 때 이를 처리하기 위해 발생
  - 시스템 콜: 어플리케이션이 OS에 서비스를 요청(입출력 작업이 필요한 경우 등)
  - ZeroDivision, 잘못된 인덱스, Overflow 등



인터럽트 처리

- CPU 관점에서
  - 인터럽트 발생
  - 인터럽트 처리 직전에 수행 중이던 작업의 상태를 **PCB에 저장**
  - 해당하는 **인터럽트 처리루틴**을 찾아서 작업 수행
    - **인터럽트 벡터**: 인터럽트 종류마다 번호를 정해 번호에 따라 처리할 코드가 위치한 부분을 가리키는 자료구조
      - x86에서는 IDT(Interrupter Discriptor Table)를 사용
      - `0x0000 ~ 0x03ff` 의 메모리 주소에 위치: 시스템 콜은 `0x80`
    - 실제 처리하는 코드는 인터럽트 처리루틴(인터럽트 핸들러)에 저장됨
  - 처리 후 **PCB로부터 작업 상태를 복원**해 실행
- 장치 관점에서
  - 컨트롤러가 인터럽트를 발생시켜 CPU에 통지



#### I/O 모델

![block](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcBveNG%2FbtqDY12Hdd0%2Fj3UtHIiNTNgy7fzVoDELl1%2Fimg.png)



블로킹/논블로킹

- 하나의 작업이 다른 작업을 막는지 안 막는지

  - 블로킹: **다른 주체의 작업이 끝날 때까지** 기다렸다가 다시 자신의 작업을 시작
    - 예) I/O 요청 시 대기 큐에 들어가면서 요청에 대한 system call이 완료된 후에 응답
  - 논블로킹: 다른 주체의 작업과 관계 없이 자신의 작업을 계속함

  

동기식/비동기식

- 별도의 수행 시작/종료시간을 갖고 있으면 비동기, 시작과 종료가 동시거나 연속이면 동기
- 동기식 입출력(synchronous I/O)
  - I/O 요청 후 입출력 작업이 완료된 후에야 제어가 사용자 프로그램에 넘어감
  - 구현 방법 1(블로킹)
    - I/O가 끝날 때 까지 CPU를 낭비시킴(idle)
    - 매시점 하나의 I/O만 일어날 수 있음
  - 구현 방법 2(논블로킹)
    - I/O가 완료될 때까지 해당 프로세스에게서 CPU를 빼앗음
    - I/O 처리를 기다리는 줄에 그 프로세스를 줄 세움
    - **다른 프로세스에게 CPU를 줌**
- 비동기식 입출력 (asynchronous I/O)
  - I/O 요청 후에도 **해당 프로세스가 계속 CPU를 할당 받아 작업**하는 것
    - 이건 비동기 논블로킹 이야기임
    - 비동기 블로킹은 동기 블로킹과 별로 다를 것이 없어서 다루지 않음
  - I/O가 시작된 후 입출력 작업이 끝나기를 기다리지 않고 제어가 사용자 프로그램에 즉시 넘어감
- 두 경우 모두 I/O의 완료는 **인터럽트로 알려줌**



## **3. 메모리 관리**



메모리 관리 방식의 종류

- 고정 분할 fixed partition
  - **각각의 분할에는 하나의 프로그램**이 적재됨
    - 동시 적재되는 최대 프로그램의 수가 분할 개수로 한정됨
  - **외부조각**발생
    - 외부조각: 분할의 크기보다 큰 프로그램은 적재가 불가능
  - **내부조각**발생
    - 내부조각: **분할 내에** 프로그램이 적재되고 남는 영역 발생
- 가변 분할 variable partition
  - 분할의 크기와 개수의 동적 관리 기법 필요: **동적 메모리 할당 문제**
    - 최초적합: 가용 공간 중 가장 먼저 찾아지는 곳에 할당
    - 최적적합: 프로세스 크기보다 큰 공간 중 **가장 작은 곳에 할당**
    - 최악적합: 가장 크기가 큰 곳에 할당
  - 외부조각 발생 가능
    - 메모리 해제 후 해당 공간에 기존 프로그램보다 작은 것이 적재되는 경우
    - **컴팩션**을 통해 해결: 사용 중인 메모리 영역을 한쪽으로 몰아 하나의 큰 공간 확보
- 가상 메모리 virtual memory
  - 물리적 **메모리보다 큰 프로그램의 실행을 지원**
    - 가상메모리 주소를 물리 메모리로 매핑
    - 현재 사용중인 부분만 메모리에 올리고 나머지는 보조기억장치에 저장



주소 바인딩

- **논리적 주소**를 물리적 메모리 주소로 연결시켜주는 작업
  - 논리적 주소: 프로세스마다 독자적으로 갖는 **가상의 메모리 주소**
- 주소가 결정되는 시기에 따른 분류
  - 컴파일 타임 바인딩
    - 컴파일할 때 주소 결정
    - 메모리 주소 변경을 위해서는 재 컴파일 필요: 현재는 잘 사용되지 않음
  - 로드 타임 바인딩
    - 프로그램의 실행이 시작될 때 주소 결정
    - **loader**(프로그램을 메모리에 적재시키는 코드)에 의해 메모리 위치 고정: 프로그램 종료까지 
    - swap out되었다가 다시 메모리에 올라갈 때도 같은 위치로 올라가야 함
  - 실행시간 바인딩 run time binding
    - 프로그램 실행중에도 메모리 주소 변경 가능
    - CPU가 주소를 참조할 때마다 **주소 매핑 테이블을 이용해야 함**
    - MMU 필요
- **Memory Management Unit**
  - 논리적 주소를 물리적 주소로 매핑해주는 하드웨어
    1. CPU가 논리적 주소를 이용해서 참조하려 함
    2. MMU가 논리 주소값에 **기준 레지스터** 값을 더해 물리 주소값을 얻음
  - 각 프로세스 별로 기준 레지스터 값과 해당 프로세스의 주소 공간의 크기를 알아야 함
    - **한계 레지스터**: 해당 프로세스의 논리적 주소의 최댓값(프로세스의 크기)



메모리 할당 방식

- 연속 할당
  - 각각의 프로세스를 물리적 메모리의 연속적인 공간에 할당
  - 고정분할 방식
    - 메모리를 고정된 크기의 분할로 미리 나눈 경우
  - 가변분할 방식
    - 프로그램의 크기에 따라 분할의 크기와 갯수를 동적으로 변화시킴
- 불연속 할당
  - 하나의 프로세스를 물리적 메모리의 **여러 영역에 분산**하여 적재
  - 불연속 할당의 기법들
    - 페이징 기법
    - 세그멘테이션 기법
    - 페이지드 세그멘테이션 기법



메모리 보안

- 사용자 프로그램이 다른 사용자 프로그램의 메모리 영역이나 커널 영역을 침범하지 못하도록 보안이 필요
- **기준 레지스터, 한계 레지스터**를 이용하여 메모리를 보호
  - 기준 레지스터: 프로그램이 접근 가능한 메모리상의 가장 작은 주소
  - 한계 레지스터: 해당 프로그램이 기준 레지스터로부터 접근 가능한 메모리의 범위
    1.  CPU의 논리 주소가 기준 레지스터보다 작은지 체크
    2.  기준 레지스터 + 한계 레지스터의 값보다 큰지도 체크
    3.  위 2개에서 해당 없으면 메모리 접근, 하나라도 해당되면 **예외상황** 발생시킴
  - 다만 이 기법은 한 프로그램이 메모리에 **연속적으로 단순하게 저장된 경우에 가능**



### 3.1. 메모리 관리 기법

페이징 기법 

- 프로세스를 **동일한 크기의 페이지 단위로 나누어** 서로 다른 위치에 저장

  - 물리적 메모리도 페이지와 동일한 크기의 **프레임**으로 미리 나누어 둠
  - 빈 프레임이 있으면 어떤 위치든 사용 가능: **동적할당문제 없음**!
  - 리눅스의 경우 4KB 단위로 메모리를 쪼갬

- 페이징 기법의 주소 변환 기법

  - 주소 변환이 복잡함: 하나의 프로세스도 페이지 단위로 올라가는 위치가 상이함

  - **각 프로세스마다** 가지는 **페이지 테이블**을 이용하여 주소 변환

    ![page table](https://i.stack.imgur.com/m3U8om.png)

    - 페이지테이블은 물리메모리(PCB) 상에 존재하며 **각 프레임의 물리 주소를 담고 있음**
    - 페이지테이블 기준 레지스터, 페이지테이블 길이 레지스터를 이용해 테이블에 접근
      1. 논리주소는 페이지 번호 p + 오프셋 d로 구성됨
      2. 페이지 번호를 이용해 테이블에서 p프레임의 시작주소를 얻음
      3. 여기에 d를 더해 원하는 데이터의 물리적 주소를 얻음
    - 따라서 CPU는 페이지테이블에 1번, 각 페이지에 1번 총 **2번 메모리 접근** 해야 함
    - 자주 참조되는 페이지의 주소를 담은 **TLB**를 사용하여 테이블 접근 오버헤드 감소시킴

  - Translation Look-aside Buffer

    - 페이지 번호와 프레임 시작주소를 key-value pair로 갖고 있음

    - parallel search가 가능한 associative register를 이용해 O(1)달성

    - 평균 메모리 접근 시간 EAT(Effective Access Time)은 다음과 같음

    - $$
      EAT = (1+\epsilon)\alpha + (2+\epsilon)(1+\alpha)
      $$

    - TLB액세스 시간은 epsilon, TLB에 정보가 있을 확률은 alpha

- 계층적 페이징

  - 페이지 테이블에 사용되는 공간 낭비를 줄이기 위해 도입

    ![two level paging](https://www.gatevidyalay.com/wp-content/uploads/2018/11/Multilevel-Paging-Illustration-Diagram-1.png)

  - 논리적 주소를 여러 종류의 페이지 번호와 오프셋으로 구분

    - 먼저 외부 페이지 테이블에서 P_1번째 인덱스에 접근해 내부 페이지 테이블 주소 획득
    - 내부 페이지 테이블에서 P_2번째 인덱스에 접근해 요청한 페이지 주소 획득
    - offset을 더해 원하는 데이터의 물리적 주소 획득
    - 2^20 * 4Byte = 4MB였던 페이지 테이블의 크기가 2 * 2^10 * 4Byte = 8KB가 됨

  - 페이지 테이블이 차지하는 공간은 줄어드나 **메모리 접근 시간 증가**하는 단점 있음

    - TLB를 이용하여 시간 단축

- 역페이지 테이블

  - **물리적 주소에 대해** 페이지 테이블 제작
  - 전체 메모리에 대해 한 테이블이 있으므로, 프로세스 번호 + 논리 페이지 번호 를 담음
    - 물리주소 -> 논리주소 변환은 쉬우나 역은 어려움
    - 테이블 내에서 요청이 들어온 논리주소를 순차탐색해야하기 때문
    - 따라서 associative register 사용

- 공유 페이지

  - 여러 프로세스에 의해 공통으로 사용되는 **공유 코드**를 담고 있는 페이지
  - 공유 페이지는 해당 페이지를 담고 있는 모든 프로세스의 주소공간에서 동일한 번호를 가짐



세그멘테이션 기법

- 프로세스의 주소 공간을 **의미 단위인 세그먼트로 분할**해서 물리 메모리에 적재
  - 크게는 프로세스 전체가 하나의 세그먼트, 일반적으로는 **코드, 데이터, 스택** 단위로 정의
  - 주소 변환을 위해 **세그먼트 테이블**을 이용함
- 세그먼트 기법의 주소 변환
  - 세그먼트 테이블의 각 항목은 **세그먼트의 시작위치와 길이**를 갖고 있음
  - 세그먼트 테이블 기준 레지스터, 세그먼트 테이블 길이 레지스터 사용해 테이블에 접근
    - 먼저 요청된 세그먼트 번호가 STLR을 넘어가는지 체크
    - 다음으로 offset값이 세그먼트 길이보다 큰지 체크
    - 위의 2개를 통과하면 메모리에 접근해 주소를 변환함
- 페이징 기법과 같은 점
  - 공유 세그먼트 개념 존재
  - 보호비트/유효비트: 각 세그먼트에 대한 접근 권한, 현재 물리 메모리에 적재되었는지 표시
- 세그먼트 기법은 **공유와 보안** 측면에서 페이징 기법보다 효과적
  - 페이징에서는 공유할 코드와 사유할 코드가 같은 페이지에 들어가는 일 등이 발생 가능
- 세그먼트 기법은 **외부조각 문제** 있음
  - 동적 메모리 할당 문제



페이지드 세그멘테이션 기법

- 프로세스를 세그먼트로 나누고, **각 세그먼트는 페이지의 집합으로 구성됨**
  - 외부의 세그먼트 테이블 + 내부의 페이지 테이블 구성
  - 논리 주소는 세그먼트 번호 + 오프셋(페이지 번호 + 페이지 내 변위값)으로 구성



### 3.2. 가상 메모리



가상 메모리란?

- 각 프로세스가 **자기 자신만이 메모리를 사용하는 것처럼 가정**하여 0번지 부터 시작하는 메모리 공간을 갖는 것
  - 프로세스에 충분한 메모리를 할당해주기 위해 도입
  - 물리적 메모리에 적재되는 부분과 **스왑 영역**에 있는 부분으로 나뉨
    - 가상 주소를 사용하고 실제 데이터를 읽고 쓸때 물리주소로 변경
    - 가상 주소 메모리 접근시 MMU가 해당 주소를 물리주소값으로 변경



가상메모리 기법

- 메모리를 적재하는 단위에 따른 분류
  - 요구 페이징
    - 일반적으로 사용됨
  - 요구 세그멘테이션
    - 페이지드 세그멘테이션의 경우에 사용됨
    - 따라서 요구 페이징 기법만이 사용된다 할 수 있음



요구 페이징 기법 *demand paging*

- 모든 데이터를 메모리에 적재하는게 아니라 **당장 필요한 데이터만 적재**
  - **선행페이징**과 반대: 프로세스 실행 데이터를 미리 적재해 둠
  - 어떤 페이지가 메모리에 적재되어 있는지 구분 필요
    - **valid-invalid bit**: 페이지 테이블의 각 항목별로 저장
    - 참조하려는 페이지가 적재되어 있지 않다(invalid): 페이지 폴트 발생

- **페이지 폴트** 
  
  - 페이지가 실제 물리메모리에 없을 때 발생하는 인터럽트
  
    1. MMU가 **page fault trap**을 발생시킴
    2. 커널모드로 전환, 프로세스 block
    3. page fault handler 호출
    4. 해당 페이지에 대한 접근이 적법한지 체크: 접근 권한, 빈 주소영역
       1. 적법하면 Storage에서 비어있는 프레임에 해당 페이지를 읽어옴
       2. 빈 프레임이 없다면 **swap out하고 해당 페이지 읽어옴**(페이지 교체)
       3. 적법하지 않으면 프로세스 종료
    5. 페이지테이블 수정
  
  - **페이지 폴트를 최소화** 하는 것이 중요
  
    - 페이지 폴트가 일어나면 Storage에 접근해야 함: 굉장히 오래 걸림
  
    - *effective access time* 으로 요구 페이징의 성능을 측정
  
    - $$
      T = (1-P)*t_m + P*t_h
      $$
  
    - P는 페이지폴트 발생 빈도, t_m은 메모리 접근 시간, t_h는 오버헤드



페이지 교체 알고리즘

- 메모리가 다 차서 페이지 폴트가 날 때 **어떤 페이지를 내릴 것인가**?

  - 목표: 페이지 부재율의 최소화
  - **앞으로 참조될 가능성이 가장 적은** 페이지를 내려야 함
  - 알고리즘의 성능은 페이지 참조열에 대해 부재율을 계산하여 평가 가능

- 알고리즘 종류

  - FIFO: 가장 먼저 들어온 페이지를 내림

    - 향후 참조 가능성을 고려하지 않아 비효율 발생 가능
    - 페이지 프레임을 늘렸는데도 페이지 폴트가 증가하는 FIFO anomaly 존재 

  - OPT: 앞으로 안 쓸 페이지를 예측(...)해서 내림

    - 물론 구현 불가: 다른 알고리즘의 **성능에 대한 상한선**을 제공함
    - Belady's optimal algorithm이라 부르기도 함

  - Least Recently Used: 가장 오래 전에 사용된 페이지를 내림

    - **시간 지역성**을 고려한 설계

  - Least Frequently Used: 가장 참조가 적게 된 페이지를 내림

    - LRU 대비 구현이 복잡하고 **시간에 따른 참조의 변화 반영 불가**
    - 참조횟수 계산 방식에 따라 Incache-LFU와 Perfect-LFU가 있음
    - Incache-LFU: 페이지가 물리메모리에 올라온 후부터의 참조횟수 계산
    - Perfect-LFU: 페이지의 과거 총 참조 횟수 카운트, 오버헤드 큼

  - Clock Algorithm: **하드웨어 지원**을 통해 알고리즘의 운영 오버헤드 감소 

    ![clock](https://examradar.com/wp-content/uploads/2019/03/Page-replacement-Algorithm-fig-2.png)

    - **시곗바늘이 한 바퀴 도는 동안 다시 참조되지 않은 페이지**를 내리는 것
    - 참조, 수정 비트를 두어 참조도 수정도 안 이루어진 페이지를 우선적으로 내림
    - NUR(Not Used Recently), NRU라고도 불림

- **교체할 프레임의 범위** 결정

  - 전역교체: 모든 프레임이 교체 대상
    - 페이지 교체 시 다른 프로세스의 프레임을 뺏어올 수 있음
    - 프로세스 별 프레임 할당량의 조절이 가능
  - 지역교체: 현재 **수행 중인 프로세스에 할당된 프레임**에서만 교체 대상 선정
    - LRU, LFU 등의 알고리즘을 프로세스별로 독자 운영할 경우



Thrashing

![스레싱](https://www2.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_18_Thrashing.jpg)

- **페이지 교체가 과도하게 일어나 CPU가동률이 급격히 하락**하는 현상

- 스레싱의 발생 이유

  - CPU가동률이 낮은 경우 운영체제는 MPD(Multi Programming Degree)를 높임
  - MPD가 과도하게 상승하면 각 **프로세스에 할당되는 메모리의 양이 지나치게 감소**
  - **메모리 양이 부족하여 페이지 폴트** 발생
  - 페이지 폴트에 따른 CPU가동률 저하로 MPD상승: 악순환 반복

- 스레싱 방지 알고리즘

  - 워킹셋 알고리즘

    ![working](https://www.informit.com/content/images/art_tanenbaum_mod04/elementLinks/tanenbaum_mod04_fig06.gif)

    - **워킹셋을 구성하는 페이지들이 한꺼번에 메모리에 올라갈 수 있는 경우에만** 해당 프로세스에 메모리를 할당
      - 워킹셋: 프로세스가 원활히 수행되기 위해 한번에 메모리에 올라와야 하는 페이지의 지역성 집합(일정 시간 동안 집중적으로 참조되는 주소 영역)
    - **워킹셋 윈도우**를 이용하여  메모리에 올라가야 할 페이지들의 집합을 결정
      - 특정 시점에서부터 일정 시간동안 참조된 페이지들의 집합을 워킹셋으로
      - 워킹셋에 포함된 페이지는 유지하고 아닌 페이지는 swap out
      - **페이지가 참조되고 일정 시간이 지나면 지워진다**고 볼 수 있음
    - MPD를 줄이는 효과
    - 프로세스가 메모리를 요구하는 정도에 따라 동적으로 할당하는 기능도 수행

  - 페이지 폴트 빈도 알고리즘

    ![pff](https://lh3.googleusercontent.com/proxy/9DJea8lzdjx1yCNHPL75CLA9kSHo7XgbOBTA8mVe6R8kOd-jRVv6tuou2AY9wYtFyQWYreRHWPwqrgj2Yy1pLcumrDlpq49nFGOTAv7gyX1aSHk3DQ)

    - 특정 프로세스의 페이지 폴트 빈도가 상한치를 넘으면 프레임을 추가로 할당
    - 반대로 하한치를 하회하면 할당된 프레임 수를 줄임



프레임 할당

- 각 프로세스에 메모리를 얼만큼 할당할지 결정하는 것이 필요
  - **정상적인 수행을 위해 일정 수준 이상의 프레임을 할당하는 것이 필요**함
  - 일부 프로세스에게는 메모리를 할당하지 않고 나머지 프로세스의 최소한의 메모리 요구량을 충족시킬 수 있어야 함
- 세 가지 기본 할당 알고리즘 존재
  - **균등할당**: 모든 프로세스에 균일하게 할당
  - **비례할당**: 프로세스의 크기에 비례해 프레임 할당
  - **우선순위 할당**: 당장 실행될 프로세스와 아닌 프로세스를 구분하여 할당





## **4. 저장매체 관리**



저장장치의 구조

- 주기억장치: 메모리
- 보조기억장치
  - 파일시스템 용
    - 전원이 나가도 유지해야 할 정보를 파일 형태로 저장
  - **스왑 영역** 용
    - 부족한 메모리를 보완
    - 프로세스에 당장 필요한 부분만 메모리에 올리고 아닌 부분은 스왑 영역에 내려둠(swap out)



메모리 계층 구조

![메모리](https://www.studytonight.com/computer-architecture/images/memory-heirarchy.png)

- **캐싱 기법**
  - 저렴하지만 느린 저장장치의(NAND, hard disk) 한계를 극복하고자 등장
  - 용량이 적고 빠른 저장장치를 이용해 느린 저장장치의 성능을 향상시키는 기법
    - 느린 저장장치에 있는 내용 중 당장 사용되거나 **빈번히 사용될 정보를 선별하여 빠른 저장장치에 저장**하여 속도를 완충시킴



### 4.1. 디스크 관리 기법



![disk](https://blog.stuffedcow.net/wp-content/uploads/2019/02/chs.svg)

디스크 스케줄링

- **여러 섹터들에 대한 I/O 요청에 대해 어떤 순서로 처리할지 결정**하는 메커니즘

- 디스크 access time은 탐색시간 + 회전지연시간 + 전송시간

  - seek time: 헤드를 해당 실린더 위치로 옮기는 시간
  - rotational latency: 섹터가 헤드 위치까지 회전하는 시간
  - transfer time: 헤드가 섹터의 데이터를 읽고 쓰는 데 걸리는 시간
  - **접근시간을 줄이기 위해서는 탐색시간을 줄여야** 함: 디스크 스케줄링의 필요성

- 스케줄링의 종류

  - FCFS: 비효율적임

  - Shortest Seek Time First

    - 현재 위치로부터 **가장 가까운 위치에 있는 요청을 먼저** 처리
    - starvation 발생 가능

  - SCAN(elevator scheduling algorithm)

    ![scan](https://gabeb1920.com/wp-content/uploads/2015/04/SCAN-Algorithm-300x207.png)

    - 디스크 **양쪽 끝을 오가면서** 해당 경로에 존재하는 모든 요청을 처리
    - 공평하고, 이동거리도 짧으나 가운데에 비해 바깥쪽이 2배로 기다려야 함

  - C-SCAN(circular)

    ![c-scan](https://gabeb1920.com/wp-content/uploads/2015/04/C-SCAN-Algorithm-300x209.png)

    - SCAN과 같이 처리하고, **끝나면 출발점으로 이동**하여 다시 처리
    - 탐색시간의 편차가 줄어듦

  - LOOK 알고리즘(사진은 C-LOOK임)

    ![look](https://gabeb1920.com/wp-content/uploads/2015/04/C-Look-Algorithm-300x209.png)

    - 헤드가 한쪽방향으로 이동하다가 그 방향에 **요청이 없으면 방향을 바꿈**
    - 가장 효율적인 것으로 알려짐

- 다중 디스크 스케줄링

  - 디스크 내에서의 트랙 결정 + 디스크 자체의 선택 문제



디스크 저전력 관리

- 디스크의 상태: active, idle, standby, sleep
  - active: 현재 헤드가 데이터를 읽고 쓰는 중
  - idle: 회전 중이지만 데이터를 읽고 쓰는 중은 아님
  - standby: 회전하지 않으나 인터페이스는 활성화됨
  - sleep: 회전하지 않고 인터페이스도 비활성화
  - 비활성 상태(standby + sleep)일 때 정지시키는 것이 효율적
- **디스크 비활성화 기법**
  - 입출력 요청 도착 시점을 예측하여 **디스크를 비활성화할 시점을 정하는 것**
  - 시간기반(timeout based) 기법
    - 일정시간 공회전하면 비활성화
    - 다시 요청이 오면 활성화
  - 예측기반(prediction based) 기법
    - 다음 공회전 구간의 길이를 예측한 후 비활성화
  - 확률기반(stochastic based) 기법
    - 확률분포를 통해 디스크의 상태변경 시간 간격을 구함
- **회전속도 조절 기법**
  - 회전속도를 가변적으로 조절해 전력 절감
  - 멀티미디어 환경의 주기성 이용, 워크로드 특성 활용 등의 기법 존재
- 데이터 배치 기법
  - 접근 속도 자체를 줄여 응답속도와 전력을 절감하는 기법
  - 복제본을 만들어 헤드에서 가까운 복제본에 접근
    - 쓰기연산 시 **일관성 문제** 발생
    - 가까운 복제본에 데이터를 쓰고 나머지 복제본에는 주소테이블에 무효화 연산
- 버퍼캐싱/사전인출 기법
  - 사전인출을 활용하여 **디스크의 상태변화를 최소화**
  - 저전력 모드일 때는 입출력을 지연시키고 정상 전력일 때 공격적으로 사전인출



### 4.2. 파일 시스템

> 운영체제가 저장매체에 파일을 쓰기 위한 자료구조/알고리즘



- 파일 시스템은 왜 만들어졌는가?
  - 비트로 관리하기엔 **오버헤드** 가 너무 큼 -> 블록 도입(1~4KB)
    - 오버헤드: 어떤 처리를 하기위해 필요한 총 시간
    - CPU사용, 메모리 사용 등이 과도하면 오버헤드 발생이라고 함
  - 블록 고유 번호 관리의 어려움으로 **논리적 객체인 파일 도입**
    - 사용자는 파일을 관리하고, 파일 내부에서는 블록이 관리됨
- 파일을 어떻게 효율적으로 저장하는가?
  - 외부 단편화 등으로 **불연속해진 공간에 최대한 채워야** 함
    - 블록체인(그거아님): 블록을 linked list로 연결
    - **인덱스 블록**: 각 블록의 위치를 기록해 블록체인의 느린 탐색 극복
- 파일 시스템 종류
  - 윈도우: FAT, FAT32, **NTFS**
    - 블록 위치를 FAT이라는 자료구조에 기록(인덱스 블록 방식)
  - LINUX: ext2, ext3, ext4
    - **inode 방식** 사용 (인덱스 블록 기법의 일종)
  - OS는 동일한 시스템 콜(`open()`)이 다양한 파일시스템에 대해 동일하게 동작하도록 작성되어야 함



inode 방식 파일 시스템 구조

- 수퍼 블록: 파일 시스템 전체에 대한 정보를 담음

  - 각 파일시스템의 위치, 이용률, 블록 갯수 등을 나타냄
  - 리눅스에서는 `$ df` 명령어로 볼 수 있음

- inode 블록: 각 파일마다 갖는 블록

  - 프로세스로 치면 PCB같은 것
  - **파일 상세정보**(메타 데이터)를 담음: 파일 생성되면 inode번호와 블록이 생김
  - 파일 권한, 소유자 정보, 사이즈, 생성시간, 저장 위치 등

- 데이터 블록: 실제 데이터

  - direct blocks, indirect blocks로 구성됨

  - 각각의 블록 안에 실제 데이터가 담김

  - blocks에 12개 블록을 저장함: 48KB는 작기 때문에 indirect block을 이용

    ![inode](https://flylib.com/books/2/849/1/html/2/images/0201702452/graphics/08fig01.gif)

    - direct blocks는 직접 12개의 블록을 가리킴
    - single indirect는 4KB의 블록을 가리키고, 해당 블록은 4byte의 **direct block pointer 1024개로 구성되어 각각 다른 블록을 가리킴**
    - double indirect는 single indirect pointer 1024개를 가리킴 



가상 파일 시스템

- Network 등 **다른 기기에 대해서도 동일한 파일 시스템 인터페이스**를 사용하도록 함
  - 다양한 파일 시스템에 대해 시스템 콜이 동일하게 동작하도록 하는 것을 확장한 것
  - 파일 시스템별 read_spec/write_spec 코드 작성에 더해 기기별로도 작성
  - 유닉스는 이를 이용해서 **모든 디바이스를 파일처럼** 다룸
    - 모든 interaction은 파일을 읽고 쓰는 것처럼 이루어짐
    - 파일 인터페이스를 모든 자원에 대한 **추상화 인터페이스**로써 활용



디바이스의 종류

- 블록 디바이스
  - HDD, CD와 같이 블록/섹터 등 **정해진 단위**로 데이터 전송
  - IO 송수신 속도 빠름
- 캐릭터 디바이스
  - 키보드 마우스와 같이 byte 단위로 데이터를 전송
  - IO 송수신 속도 느림



## **5. 기타**



### 5.1. 웹캐싱



[HTTP caching MDN](https://developer.mozilla.org/ko/docs/Web/HTTP/Caching)



### 5.2. 부팅

> 컴퓨터를 켜서 동작시키는 절차



부트 프로그램

- 커널을 storage에서 물리 메모리로 복사하고 커널의 처음 실행위치로 PC를 가져다 놓는 프로그램
- 프로그램은 메모리에서 CPU에 가져가는건데 메모리가 비었음, 누가 함?
  - **BIOS가 함**
    1. 컴퓨터 켜면 CPU가 ROM내의 특정 주소(`FFFF0H`)를 읽음: BIOS
    2. BIOS 프로그램의 일부가 실행되어 BIOS 코드를 메모리에 로드
    3. 메모리에 올라간 BIOS는 하드웨어를 초기화하고, **MBR**을 읽어 옴
    4. **부트 로더**를 메모리에 로드하고, **파티션 테이블**을 읽어 **부트 섹터**를 찾아감
    5. 부트 섹터에서 **부트 코드**를 로드함
    6. 부트 코드가 **커널 이미지**(OS 실행파일)를 메모리에 로드함
    7. 커널이 실행됨
  - Master Boot Record
    - 저장매체의 맨 앞에 위치함
    - boot loader, 파티션 테이블이 존재함
  - 파티션 테이블
    - 저장매체의 파티션에 대한 정보를 담고 있고, 무엇이 메인파티션인지 담고 있음
    - OS가 저장되어 있는 메인 파티션에는 **부트섹터**가 존재함
  - 부트섹터
    - 부트 코드가 저장되어 있음 



### 5.3 가상머신

> 하나의 하드웨어에 다수의 OS를 설치하고 개별 컴퓨터처럼 동작하도록 하는 프로그램



- 구조
  
  - 하드웨어 위의 가상머신이 **자신이 하드웨어인 것처럼**(에뮬레이트) 동작
  - **하이퍼바이저**를 사용하고 OS가 추가로 필요하여 **성능 저하** 존재
    - 하이퍼바이저(VMM): OS와 어플리케이션을 하드웨어에서 분리하는 프로세스
  
  ![vm](https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter2/16_1_Virtual_Models.jpg)
  
- 가상머신의 종류
  - 타입1: native or bare metal
    - 타입 1에서는 하이퍼바이저가 하드웨어에서 직접 구동
    - 하드웨어에 직접 액세스하기 때문에 **가장 성능이 좋음**
    - Xen, **KVM**(AWS 등에서 사용함)
  - 타입2
    - 이미 설치되어 있는 운영체제(HOST OS) 위에 VMM이 설치됨
    - 타입 1 대비 느림: 어플리케이션이 운영체제-VMM-HOST OS를 거쳐야 함
    - **VMWare**(윈도우 환경에서 리눅스를 사용할 때 많이 이용), Parallels Desktop
  - 전가상화
    - 하이퍼바이저가 가상머신과 하드웨어의 통역을 수행
    - VMM이 하드웨어인 것처럼 동작: **가상머신의 OS는 자신이 가상 머신인 줄 모름**
  - 반가상화
    - 각 가상머신이 직접 하드웨어와 통신
    - 각 OS는 자신이 가상 머신임을 인지하고 명령에 하이퍼바이저 명령을 추가해 하드웨어와 통신
    - 이 때 VMM은 리소스 관리만 하게 됨: 전가상화 대비 빠름



**Docker**

![docker](https://wiki.aquasec.com/download/attachments/2854889/Container_VM_Implementation.png?version=1&modificationDate=1520172703952&api=v2)

- 가상머신이 하드웨어를 추상화한다면 도커는 **커널을 추상화** 함
  - **리눅스 컨테이너** 기술 이용
    - `chroot` 명령어를 이용하여 OS레벨에서 별도로 분리된 실행환경을 만들 수 있음
    - 해당 공간을 이용해 리눅스를 처음 설치했을 때와 같은 실행환경을 만들어 줌
  - 리눅스 커널 안에 있는 기능으로 리눅스 설치 필요
    - macOS나 Windows에서는 가상머신 필요;
- 여러가지 **실행환경을 통채로 백업** 가능: 실무에 많이 사용됨(파이썬에서 `venv`를 썼듯이...)
  - 복잡한 실행환경에서 작성된 프로그램은 Docker 환경설정+프로그램을 한번에 배포
  - 프로그램 업데이트 -> Docker 이미지 작성 -> **Jenkins**로 배치잡 생성/실행

- JVM
  - 응용프로그램 레벨에서의 가상화: 엄밀하게 가상머신은 아님
  - CPU에 의존적이지 않은 bytecode를 생성할 목적으로 만들어짐
    - 생성된 bytecode는 JVM에서 각 운영체제에 맞게 명령을 내림